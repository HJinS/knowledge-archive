{
  "main": {
    "id": "42b4060f716dd85e",
    "type": "split",
    "children": [
      {
        "id": "c8b6f927f34e357e",
        "type": "tabs",
        "children": [
          {
            "id": "9a01b66cee089ddb",
            "type": "leaf",
            "state": {
              "type": "graph",
              "state": {}
            }
          },
          {
            "id": "417a2404825df809",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "강화학습/마르코프 결정 과정/행동 가치 함수(Q함수).md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "51841812199fbc0a",
            "type": "leaf",
            "state": {
              "type": "release-notes",
              "state": {
                "currentVersion": "1.5.3"
              }
            }
          },
          {
            "id": "08ebd692c8a92d2f",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "강화학습/마르코프 결정 과정/마르코프 결정 과정(MDP).md",
                "mode": "source",
                "source": false
              }
            }
          },
          {
            "id": "b6b3b39d6c5a802b",
            "type": "leaf",
            "state": {
              "type": "excalidraw",
              "state": {
                "file": "Excalidraw/MRP MDP 비교.md"
              }
            }
          }
        ],
        "currentTab": 2
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "683e85b67e219b05",
    "type": "split",
    "children": [
      {
        "id": "f16a9a58851516fa",
        "type": "tabs",
        "children": [
          {
            "id": "f4c8331144ca74ab",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "565ee18e9d577db5",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "6b38efb65963d332",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {}
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300
  },
  "right": {
    "id": "139a28550ebad043",
    "type": "split",
    "children": [
      {
        "id": "4703b640e849fd18",
        "type": "tabs",
        "children": [
          {
            "id": "b4e0e85b554713a5",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "강화학습/마르코프 결정 과정/행동 가치 함수(Q함수).md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "801f1eb1d8252acf",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "강화학습/마르코프 결정 과정/행동 가치 함수(Q함수).md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "d5f7d3c314bc543e",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              }
            }
          },
          {
            "id": "d66e3532e5564159",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "강화학습/마르코프 결정 과정/행동 가치 함수(Q함수).md"
              }
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "obsidian-projects:Open projects": false,
      "obsidian-full-calendar:Open Full Calendar": false,
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false,
      "obsidian-excalidraw-plugin:Create new drawing": false
    }
  },
  "active": "51841812199fbc0a",
  "lastOpenFiles": [
    "강화학습/마르코프 결정 과정/상태 가치 함수(MDP).md",
    "강화학습/마르코프 결정 과정/정책.md",
    "강화학습/마르코프 결정 과정/행동 가치 함수(Q함수).md",
    "강화학습/마르코프 보상 과정/마르코프 속성.md",
    "강화학습/마르코프 보상 과정/마르코프 연쇄.md",
    "강화학습/마르코프 보상 과정/감가율.md",
    "강화학습/마르코프 보상 과정/상태 전이 메트릭스.md",
    "강화학습/마르코프 보상 과정/반환값.md",
    "강화학습/마르코프 보상 과정/벨만 방정식.md",
    "강화학습/마르코프 보상 과정/보상 함수.md",
    "강화학습/마르코프 보상 과정/상태 가치 함수(MRP).md",
    "강화학습/마르코프 결정 과정/보상 함수와 상태 전이 매트릭스(MDP).md",
    "강화학습/마르코프 결정 과정/마르코프 결정 과정(MDP).md",
    "강화학습/마르코프 보상 과정/마르코프 보상 과정(MRP).md",
    "보상.md",
    "강화학습/마르코프 보상 과정/환경.md",
    "README.md",
    "Excalidraw/MRP MDP 비교.md",
    "MDP.md",
    "Excalidraw/보상함수 샘플.md",
    "에이전트.md",
    "Untitled.canvas",
    "강화학습/마르코프 결정 과정",
    "Untitled.md",
    "강화학습/마르코프 보상 과정",
    "Excalidraw",
    "Excalidraw/Drawing 2023-12-07 09.19.48.excalidraw.md",
    "$S$.md",
    "감가율.md",
    "강화학습"
  ]
}