# 상태 가치 함수($v$: State Value Function)
[[반환값]]으로 에피소드 하나에 대한 가치를 측정 할 수 있다면, 상태 가치 함수로는 **환경 전체**에 대한 가치를 측정 할 수 있다. 함수라는 용어에서 짐작 할 수 있듯이 상태가치 함수에서는 **상태 전이 확률**을 같이 고려한다.
> 수식
> 1. $v(s) = E[G_t | S_t = s]$
> 2. $v(s) = E[R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + ... | S_t = s]$
> 3. $v(s) = E[R_{t+1} + \gamma(R_{t+2} + \gamma R_{t+3} + ...) | S_t = s]$
> 4. $v(s) = E[R_{t+1} + \gamma G_{t+1} | S_t = s]$
> 5. $v(s) = E[R_{t+1} + \gamma v(S_{t+1}) | S_t = s]$

> 1. 타임스텝 t에서 상태가 s일 때 상태 가치 함수는 [[반환값]]에 대한 기대값으로 구할 수 있다.
> 2. [[반환값]]을 구하는 수식을 대입
> 3. 다음 스텝의 [[반환값]]을 감가율로 묶은 것
> 4. 3번의 결과를 다시 다음 스텝의 반환값으로 대치
> 5. 반환값 $G_{t+1}$대신에 상태 가치 함수($v(S_{t+1})$)를 대입
> 	1. 반환값에 대한 기대값을 구하면 **상태 가치 함수**를 구하는 것과 같다.
> 	2. 기대값을 구하는 상황에서는 반환값과 상태 가치 함수가 같은 역할을 한다.꼐