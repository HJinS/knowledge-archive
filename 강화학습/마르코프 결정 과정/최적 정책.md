**최적 정책**이란 어떠한 정책보다 값이 크다.
- 정책이란 행동을 선택 할 수 있는 확률이기 때문에, 값이 크다는 것은 확률이 높다는 이야기이다.

1. 최적 정책을 사용해서 구한 [[상태 가치 함수(MDP)]]수의 값은 [[최적 상태 가치 함수]]의 값과 같다. 
2. 최적 정책을 사용해서 구한 [[행동 가치 함수(Q함수)]]의 값은 [[최적 행동 가치 함수]]의 값과 같다.

$$
\pi(a|s)=
\begin{cases}
    1, & if a = argmax_{a \in A}q^*(s,s) \newline
    0, & \text{Otherwise}
\end{cases}
$$

> 하나의 행동이 [[최적 행동 가치 함수]]의 최댓값을 반환하게 만드는 행동과 같다면 최적 해당 행동에 대한 정책은 1이고, 그렇지 않을 경우 행동에 대한 정책은 0이 된다.